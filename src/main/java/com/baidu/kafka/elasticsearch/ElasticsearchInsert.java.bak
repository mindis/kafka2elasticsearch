package com.baidu.kafka.elasticsearch;

import kafka.consumer.ConsumerIterator;
import kafka.consumer.KafkaStream;
import kafka.message.MessageAndMetadata;
import java.util.*;
import java.text.SimpleDateFormat;
import java.util.Map;
import java.util.Date;
import java.lang.Double;
import java.lang.Long;
import java.lang.String;
import java.util.HashMap;
import java.lang.Integer;

import org.elasticsearch.action.index.IndexResponse;
import org.elasticsearch.client.Client;
import org.elasticsearch.client.transport.TransportClient;
import org.elasticsearch.common.settings.ImmutableSettings;
import org.elasticsearch.common.settings.Settings;
import org.elasticsearch.common.transport.InetSocketTransportAddress;
import org.elasticsearch.action.bulk.BulkRequestBuilder;
import org.elasticsearch.action.bulk.BulkResponse;
import org.elasticsearch.action.search.SearchResponse;
import org.elasticsearch.action.search.SearchType;
import org.elasticsearch.index.query.QueryBuilder;
import org.elasticsearch.index.query.FilterBuilders;
import org.elasticsearch.index.query.QueryBuilders;
import org.elasticsearch.search.SearchHit;
import org.elasticsearch.search.SearchHits;
import org.elasticsearch.action.get.GetResponse;
import org.elasticsearch.action.admin.cluster.node.info.NodeInfo;
import org.elasticsearch.action.admin.cluster.node.info.NodesInfoRequest;
import org.elasticsearch.action.admin.cluster.node.info.NodesInfoResponse;
import static org.elasticsearch.node.NodeBuilder.*;

import org.json.JSONObject;
import com.baidu.kafka.elasticsearch.ConfigFile;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

@SuppressWarnings("rawtypes")
public class ElasticsearchInsert implements Runnable {
  private KafkaStream stream;
  private int threadNumber;
  private String kafkaMsg;
  protected String productName;
  protected String serviceName;
  protected TransportClient client;
  protected String indexName;
  protected String typeName;
  protected Map<String,NodeInfo> nodesMap = new HashMap<>();
  protected String elasticSearchHost = ConfigFile.ES_HOSTS;
  protected Integer elasticSearchPort = ConfigFile.ES_PORT;
  protected String elasticSearchCluster = ConfigFile.ES_CLUSTER_NAME;
  protected static Logger LOG = LoggerFactory.getLogger(ElasticsearchInsert.class);

  public ElasticsearchInsert(KafkaStream stream, String esHost) {
    this.stream = stream;
    elasticSearchHost = esHost;
    Settings settings = ImmutableSettings.settingsBuilder().put("cluster.name", elasticSearchCluster).build();
    client = new TransportClient(settings).addTransportAddress(new InetSocketTransportAddress(elasticSearchHost, elasticSearchPort));
    NodesInfoResponse response = client.admin().cluster().nodesInfo(new NodesInfoRequest().timeout("60")).actionGet();
    nodesMap = response.getNodesMap();
    for(String k: nodesMap.keySet()){
    if(!elasticSearchHost.equals(nodesMap.get(k).getHostname())) {
       client.addTransportAddress(new InetSocketTransportAddress(nodesMap.get(k).getHostname(), elasticSearchPort));
      }
    }
  }

  public boolean insertES(JSONObject jsonb) {
    String document = null;
    try {
         document = jsonb.toString();
         BulkRequestBuilder bulkRequest = client.prepareBulk();
         bulkRequest.add(this.client.prepareIndex(indexName, typeName).setSource(document));
         BulkResponse bulkItemResponses = bulkRequest.execute().actionGet();
         return true;
    } catch(Exception e) {
         LOG.info("Unable to index Document[ " + document + "], Type[" + typeName + "], Index[" + indexName + "]", e);
         return false;
    }
  }

  public void run() {
    LOG.info("Inert ElasticSearch"); 
    ConsumerIterator<byte[], byte[]> msgStream = stream.iterator();
    while(msgStream.hasNext()) {
      try {
          //System.out.println("kafka msg-----");
	  kafkaMsg = new String(msgStream.next().message(), "UTF-8");
          //System.out.println(kafkaMsg);
	  JSONObject json = new JSONObject(kafkaMsg);
	  productName = json.getString("product");
	  serviceName = json.getString("service");
	  //productName = "sf";
	  //serviceName = "bfe";
	  //if(!serviceName.equals("bfe")) {
	  //   continue;
	  //}
	  long insertTime = System.currentTimeMillis();
	  long eventTime = json.getLong("event_time");
	  long cacheTime = json.getLong("cache_time");
	  json.put("insert_time", insertTime);
	  SimpleDateFormat sf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
	  String dateTime = sf.format(eventTime);
	  String dateTimeYMD[] = dateTime.split(" ");
          indexName = "aqueducts_" + productName + "_" + dateTimeYMD[0];
          //indexName = "aqueducts_" + productName + "_2014-09-28";
	  typeName = serviceName;
	  /*
          for(String k : nodesMap.keySet()){
             LOG.info(k + ":" + nodesMap.get(k).getHostname());
	  }*/
	  //System.out.println("index:"+indexName+" type:"+typeName);
	  LOG.info("kafka-es's delay:"+(insertTime-cacheTime));
	  
	  if(insertES(json)) {
	     LOG.info("Document[ " + json.toString() + "], System's Delay[" + (insertTime-eventTime)/1000 +"]");
	  }
      } catch (Exception e) {
          LOG.info("failed to construct index request "+ e.getMessage());
      }
    }
  }
}
